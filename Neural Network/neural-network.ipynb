{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nclass NeuralNetwork:\n    \n    def __init__(self,input_size,layers,output_size):\n        np.random.seed(0)\n        \n        model = {} #Dictionary\n        \n        #First Layer\n        model['W1'] = np.random.randn(input_size,layers[0])\n        model['b1'] = np.zeros((1,layers[0]))\n        \n        #Second Layer\n        model['W2'] = np.random.randn(layers[0],layers[1])\n        model['b2'] = np.zeros((1,layers[1]))\n        \n        #Third/Output Layer\n        model['W3'] = np.random.randn(layers[1],output_size)\n        model['b3'] = np.zeros((1,output_size))\n        \n        self.model = model\n        self.activation_outputs = None\n    \n    def forward(self,x):\n        \n        W1,W2,W3 = self.model['W1'],self.model['W2'],self.model['W3']\n        b1, b2, b3 = self.model['b1'],self.model['b2'],self.model['b3']\n        \n        z1 = np.dot(x,W1) + b1\n        a1 = np.tanh(z1) \n        \n        z2 = np.dot(a1,W2) + b2\n        a2 = np.tanh(z2)\n        \n        z3 = np.dot(a2,W3) + b3\n        y_ = softmax(z3)\n        \n        self.activation_outputs = (a1,a2,y_)\n        return y_\n        \n    def backward(self,x,y,learning_rate=0.001):\n        W1,W2,W3 = self.model['W1'],self.model['W2'],self.model['W3']\n        b1, b2, b3 = self.model['b1'],self.model['b2'],self.model['b3']\n        m = x.shape[0]\n        \n        a1,a2,y_ = self.activation_outputs\n        \n        delta3 = y_ - y\n        dw3 = np.dot(a2.T,delta3)\n        db3 = np.sum(delta3,axis=0)\n        \n        delta2 = (1-np.square(a2))*np.dot(delta3,W3.T)\n        dw2 = np.dot(a1.T,delta2)\n        db2 = np.sum(delta2,axis=0)\n        \n        delta1 = (1-np.square(a1))*np.dot(delta2,W2.T)\n        dw1 = np.dot(X.T,delta1)\n        db1 = np.sum(delta1,axis=0)\n        \n        \n        #Update the Model Parameters using Gradient Descent\n        self.model[\"W1\"]  -= learning_rate*dw1\n        self.model['b1']  -= learning_rate*db1\n        \n        self.model[\"W2\"]  -= learning_rate*dw2\n        self.model['b2']  -= learning_rate*db2\n        \n        self.model[\"W3\"]  -= learning_rate*dw3\n        self.model['b3']  -= learning_rate*db3","metadata":{"_uuid":"80439500-b130-45b8-8c0f-1c5327b303fa","_cell_guid":"8d7e6d13-fa85-4101-ba74-cb8de0993e0a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-19T07:22:39.838009Z","iopub.execute_input":"2021-07-19T07:22:39.838454Z","iopub.status.idle":"2021-07-19T07:22:39.859814Z","shell.execute_reply.started":"2021-07-19T07:22:39.838417Z","shell.execute_reply":"2021-07-19T07:22:39.858186Z"},"trusted":true},"execution_count":3,"outputs":[]}]}